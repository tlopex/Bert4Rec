{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2dad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "# # 读取 CSV 文件\n",
    "# df = pd.read_csv('data_with_next_item.csv')\n",
    "\n",
    "# # 将 DataFrame 转换为 Parquet 表\n",
    "# table = pa.Table.from_pandas(df)\n",
    "\n",
    "# # 将 Parquet 表写入到 Parquet 文件\n",
    "# pq.write_table(table, 'output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2037bded",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat_tables() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2a57a1569585>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmerged_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mmerged_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmerged_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rows'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# 将合并的结果数据集写入新的 Parquet 文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pyarrow\\table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.concat_tables\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: concat_tables() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# 定义要合并的多个 Parquet 文件的文件路径\n",
    "file_paths = ['result1.parquet', 'result2.parquet', 'result3.parquet']\n",
    "\n",
    "# 创建一个空的 Parquet 数据集作为合并结果\n",
    "merged_dataset = None\n",
    "\n",
    "# 逐个读取并追加合并 Parquet 文件\n",
    "for file_path in file_paths:\n",
    "    # 读取 Parquet 文件\n",
    "    dataset = pq.read_table(file_path)\n",
    "    \n",
    "    # 追加合并到结果数据集\n",
    "    if merged_dataset is None:\n",
    "        merged_dataset = dataset\n",
    "    else:\n",
    "        merged_dataset = pa.concat_tables([merged_dataset, dataset],axis='rows')\n",
    "\n",
    "# 将合并的结果数据集写入新的 Parquet 文件\n",
    "output_file = 'merged.parquet'\n",
    "pq.write_table(merged_dataset, output_file)\n",
    "\n",
    "print(\"合并完成并写入：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c7348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c296550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e1d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42354aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# 读取多个 Parquet 文件并合并为一个 DataFrame\n",
    "dfs = []\n",
    "file_paths = ['result1.parquet', 'result2.parquet', 'result3.parquet']  # 替换为实际的文件路径列表\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_parquet(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs)\n",
    "\n",
    "# 创建一个新的 Parquet 文件\n",
    "output_file = \"merged_file.parquet\"  # 替换为输出文件的路径和名称\n",
    "pq.write_table(pa.Table.from_pandas(merged_df), output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb20303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e04000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     next_item_prediction\n",
      "0       [B0B2X1V65K, B0832WLDLC, B08K9WQ849, B08R3JCJH...\n",
      "1       [B0B5YZLFMM, B00MRNHFDS, B00P0C4M3Y, B097TVV25...\n",
      "2       [B07ZT2YR4L, B09K445HXZ, B07YYT82BZ, B082YF1SC...\n",
      "3       [B07YYT82BZ, B07GRMNDW1, B012VPXQ7A, B08LVMKKT...\n",
      "4       [B0BBZHY37F, B01MRXGEV7, B0B2X1V65K, B07ZX2KVZ...\n",
      "...                                                   ...\n",
      "115932  [B00VG0KBJI, B0025ST14G, B082XNNNZ2, B09L9Q751...\n",
      "115933  [B07P74YCNB, B08MTS969S, B09C96J8TT, B08XY59JQ...\n",
      "115934  [B0915Z4B1H, B08F2BH449, B08P6NDDGZ, B099WTY9D...\n",
      "115935  [B0B1DBLKK1, B00AXA4PJ4, B084Q79DV4, B015RE5OB...\n",
      "115936  [B0BFP91YTH, B07N2XFWR1, B00BPBWY34, B000OQ66L...\n",
      "\n",
      "[316972 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327f48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
